---
date: 2024-07-25
last_modified: 2024-07-25
title: "Mapping CVEs to MITRE ATT&CK"
description: "Being able to label CVEs with ATT&CK data allows for rich filtering, e.g. what CVEs use ATT&CK Technique X?. Here's how to create those labels in STIX 2.1."
categories:
  - PRODUCTS
  - DIY
tags: [
    STIX
]
products:
    - stix2arango
    - cve2stix
    - arango_cti_processor
    - CTI Butler
author_staff_member: david-greenwood
image: /assets/images/blog/2024-07-25/header.png
featured_image: /assets/images/blog/2024-07-25/header.png
layout: post
published: true
redirect_from:
  - 
---

## tl;dr

Take CVEs in STIX format. Take ATT&CK data in STIX format. Join them using STIX SROs. Search for CVEs by ATT&CK IDs.

## Overview

[I have described previously about how CTI Butler joins data from different knowledgebase](/blog/cti_knowledge_base_graph).

One of the features I've recently being working on is linking the 200k+ CVE objects in CTI Butler to ATT&CK (it already links them to Sigma Rules, CWEs and CPEs).

Imagine being able to begin a hunt by asking; which CVEs published in the last month are using the ATT&CK Enterprise Technique, Content Injection (T1659)? Which CVEs are using PACEMAKER (S1109)? [Or any of the other object types reported by ATT&CK](/blog/mitre_attack_data_structure).

Of course this not only allows you to pivot on CVEs using ATT&CK, but also any other information you might hold that is linked into MITRE ATT&CK (e.g. you might be tracking actors using ATT&CK tools, etc.).

The problem is, how do you take a CVE and link it ATT&CK.

## Getting CVE data

[CTI Butler](https://www.ctibutler.com/) already holds all published CVEs in STIX 2.1 format ([generated by cve2stix](https://github.com/muchdogesec/cve2stix)).

For this use-case we only case about the Vulnerability object (because these contain the most descriptive information about each CVE).

For example to get all CVEs published in 2018;

```sql
FOR doc IN nvd_cve_vertex_collection
    FILTER doc.type == "vulnerability"
    AND doc.revoked != true
    AND doc.created >= "2020-01-01T00:00:00.000Z" AND doc.created <= "2020-12-31T23:59:59.999Z"
    COLLECT WITH COUNT INTO length
    RETURN length
```

```json
[
  18304
]
```

For demo purposes, lets look at a smaller subset of `description` for CVEs published in January 2020.

```sql
FOR doc IN nvd_cve_vertex_collection
    FILTER doc.type == "vulnerability"
    AND doc.revoked != true
    AND doc.created >= "2020-01-01T00:00:00.000Z" AND doc.created <= "2020-01-31T23:59:59.999Z"
    RETURN {
        id: doc.id,
        cve: doc.name,
        published: doc.created,
        modified: doc.modified,
        description: doc.description
        }
```

(this generates over 1000 results, so we need to page through them, as only 1000 will be returned by this query)

```json
[
  {
    "id": "vulnerability--7256211c-e7f8-521b-af2e-9575690af8f1",
    "cve": "CVE-2019-15985",
    "published": "2020-01-06T08:15:11.503Z",
    "modified": "2020-01-08T20:55:54.203Z",
    "description": "Multiple vulnerabilities in the REST and SOAP API endpoints of Cisco Data Center Network Manager (DCNM) could allow an authenticated, remote attacker to execute arbitrary SQL commands on an affected device. To exploit these vulnerabilities, an attacker would need administrative privileges on the DCNM application. For more information about these vulnerabilities, see the Details section of this advisory. Note: The severity of these vulnerabilities is aggravated by the vulnerabilities described in the Cisco Data Center Network Manager Authentication Bypass Vulnerabilities advisory, published simultaneously with this one."
  },
  {
    "id": "vulnerability--620f4cb1-67db-57bb-b7b0-81f6c1b45519",
    "cve": "CVE-2016-6587",
    "published": "2020-01-08T18:15:10.213Z",
    "modified": "2020-01-13T19:50:15.777Z",
    "description": "An Information Disclosure vulnerability exists in the mid.dat file stored on the SD card in Symantec Norton Mobile Security for Android before 3.16, which could let a local malicious user obtain sensitive information."
  },
  {
    "id": "vulnerability--a68f7180-2a48-520c-b027-19a4404e3eaa",
    "cve": "CVE-2015-5952",
    "published": "2020-01-15T17:15:13.537Z",
    "modified": "2020-01-22T15:28:32.637Z",
    "description": "Directory traversal vulnerability in Thomson Reuters for FATCA before 5.2 allows remote attackers to execute arbitrary files via the item parameter."
  },
```

Side note, you might be wondering why a CVE with ID `CVE-2015-5952` was publushed in 2020. I am not to sure either, but this is the date being reported as the `created` time by the NVD CVE API that cve2stix uses to assign `published` value

```shell
curl --location 'https://services.nvd.nist.gov/rest/json/cves/2.0?cveId=CVE-2015-5952'
```

```json
{
    "resultsPerPage": 1,
    "startIndex": 0,
    "totalResults": 1,
    "format": "NVD_CVE",
    "version": "2.0",
    "timestamp": "2024-06-15T15:07:46.420",
    "vulnerabilities": [
        {
            "cve": {
                "id": "CVE-2015-5952",
                "sourceIdentifier": "cve@mitre.org",
                "published": "2020-01-15T17:15:13.537",
                "lastModified": "2020-01-22T15:28:32.637",
```

Now, above I've only shown searches that get a subset of data. This script below will get you all CVE records in a .csv file from [CTI Butler](https://www.ctibutler.com/), ready for the next step (make sure to replace `USERNAME` and `PASSWORD`);

```python
import csv
import requests

# Configuration
arangodb_host = "https://database.ctibutler.com:8529"
database_name = "cti_database"
arangodb_user = "USERNAME"
arangodb_password = "PASSWORD"
chunk_size = 1000  # Number of documents per page

# AQL query template
aql_query = """
FOR doc IN nvd_cve_vertex_collection
    FILTER doc.type == "vulnerability"
    SORT doc.modified DESC
    RETURN {
        id: doc.id,
        modified: doc.modified,
        name: doc.name,
        description: doc.description
    }
"""

# Initialize CSV file
csv_file = "nvd_cve_vertex_collection.csv"
csv_headers = ["id", "modified", "name", "description"]

with open(csv_file, mode='w', newline='', encoding='utf-8') as file:
    writer = csv.DictWriter(file, fieldnames=csv_headers)
    writer.writeheader()

    # Pagination loop using cursor
    query_url = f"{arangodb_host}/_db/{database_name}/_api/cursor"
    response = requests.post(query_url, json={"query": aql_query, "batchSize": chunk_size}, auth=(arangodb_user, arangodb_password))
    response.raise_for_status()

    result = response.json()
    total_fetched = 0

    while True:
        documents = result.get("result", [])

        # Write the current chunk to the CSV file
        if documents:
            for doc in documents:
                writer.writerow(doc)
            total_fetched += len(documents)
            print(f"Fetched {len(documents)} documents, total fetched: {total_fetched}")
        else:
            break

        # Check if we have more documents to fetch
        if not result.get("hasMore"):
            break

        # Fetch the next batch using the cursor ID
        cursor_id = result.get("id")
        response = requests.put(f"{query_url}/{cursor_id}", auth=(arangodb_user, arangodb_password))
        response.raise_for_status()
        result = response.json()

print(f"Total fetched documents: {total_fetched}")
print(f"Results have been written to {csv_file}")
```

The csv file will look like this;

```txt
id,modified,name,description
vulnerability--a6069912-af3f-5775-98f7-e810c11df4a9,2024-06-30T23:15:02.563Z,CVE-2024-1135,"Gunicorn fails to properly validate Transfer-Encoding headers, leading to HTTP Request Smuggling (HRS) vulnerabilities. By crafting requests with conflicting Transfer-Encoding headers, attackers can bypass security restrictions and access restricted endpoints. This issue is due to Gunicorn's handling of Transfer-Encoding headers, where it incorrectly processes requests with multiple, conflicting Transfer-Encoding headers, treating them as chunked regardless of the final encoding specified. This vulnerability allows for a range of attacks including cache poisoning, session manipulation, and data exposure."
vulnerability--ca2fca16-3e75-5bce-b90c-d8092572f236,2024-06-30T23:15:02.443Z,CVE-2023-48733,An insecure default to allow UEFI Shell in EDK2 was left enabled in Ubuntu's EDK2. This allows an OS-resident attacker to bypass Secure Boot.
```

## Using an AI model to map descriptions to ATT&CK objects

Most `description` values for CVEs are very short.

Though I am still confident a well trained AI model will be more than capable.

As a POC I'll start with a generic model, GPT-4o;

```
In the following prompts I will provide data as follows

{
    "cve_id": "<CVE ID>",
    "cve_description": "<CVE DESCRIPTION>"
}

For each record I want you to describe which MITRE ATT&CK objects are being described in the cve_description?

Be as specific as you can when assigning MITRE ATT&CK classifications. Use the description of the ATT&CK objects when classifying them against the CVE description provided in the prompt.

For example, if the text contained 'Android' it is not specific enough to link it to an ATT&CK object, but it is useful in determining the domain, mobile. Another example, if the text contained 'Started to download data from an Android device', it would be highly indicative of TA0036, Exfiltration.

Similarly, text like 'obtain sensitive information' is not enough information to assign an ATT&CK classification. However, 'obtain sensitive information by taking screenshots', would be highly indicative of T1513, Screen Capture.

It could be the case that the CVE description is not descriptive enough to assign any ATT&CK classifications.

For each ATT&CK object identified, print your response as only JSON in the following structure:

{
    "CVE_ID": {
        "detected_objects": [
        {
            attack_domain: "DOMAIN",
            attack_id: "ID",
            attack_name: "NAME",
            confidence_score: "SCORE",
            analysis: "WHY YOU CAME TO THIS DECISION"
        },
        {
            attack_domain: "DOMAIN",
            attack_id: "ID",
            attack_name: "NAME",
            confidence_score: "SCORE",
            analysis: "WHY YOU CAME TO THIS DECISION"
        }
    ]
}

Where confidence score defines how sure you are this object is being described in the text (between 0 [lowest] and 1 [highest])
```

Lets try the above command with the description of CVE-2016-6587:

> An Information Disclosure vulnerability exists in the mid.dat file stored on the SD card in Symantec Norton Mobile Security for Android before 3.16, which could let a local malicious user obtain sensitive information.

Which GPT-4o returns;

```json
{
    "CVE-2016-6587": {
        "detected_objects": [
        {
            "attack_domain": "Enterprise",
            "attack_id": "T1005",
            "attack_name": "Data from Local System",
            "confidence_score": 0.9,
            "analysis": "Text contains 'the mid.dat file stored on the SD card'"
        },
        {
            "attack_domain": "Enterprise",
            "attack_id": "T1586",
            "attack_name": "Compromise Accounts",
            "confidence_score": 0.7,
            "analysis": "Text contains 'which could let a local malicious user obtain sensitive information'"
        },
        {
            "attack_domain": "Enterprise",
            "attack_id": "T1589",
            "attack_name": "Gather Victim Identity Information",
            "confidence_score": 0.7,
            "analysis": "Text contains 'which could let a local malicious user obtain sensitive information'"
        }
    ]
}
```

At this point I'm not looking for model accuracy because the model can be swapped out easily as required (I'd argue this output is fairly poor). Why? We have some much better locally trained models on ATT&CK data. There are also better off-the-shelf models available to you, e.g. [those that ship with TRAM](/blog/getting_started_mitre_tram).

The point being is the general concept here works, and also allows me to set a confidence threshold in my code for allowing only high confidence ATT&CK matches.

## If you want to make a public model more accurate

HOWEVER, I do appreciate that many reading this won't have the resources, datasets, or time to train a model. This is where retrieval-augmented generation (RAG) can help.

To do this you can use CTI Butler to grab a list of all relevant ATT&CK objects you want the AI to be aware of;

```python
import csv
import requests

# Configuration
arangodb_host = "https://database.ctibutler.com:8529"
database_name = "cti_database"
arangodb_user = "USERNAME"
arangodb_password = "PASSWORD"
chunk_size = 1000  # Number of documents per page

collections = [
    "mitre_attack_enterprise_vertex_collection",
    "mitre_attack_ics_vertex_collection",
    "mitre_attack_mobile_vertex_collection"
]

aql_template = """
FOR doc IN {collection}
  FILTER doc._stix2arango_note != "automatically imported on collection creation"
  AND doc._stix2arango_note == "v15.1"
  AND (
    doc.type == "x-mitre-tactic" OR 
    doc.type == "attack-pattern" OR 
    doc.type == "course-of-action" OR 
    doc.type == "intrusion-set" OR 
    doc.type == "malware" OR 
    doc.type == "tool" OR 
    doc.type == "campaign" OR 
    doc.type == "x-mitre-data-source"
  )
  LET attack_id = (
    FOR extRef IN (FOR ref IN doc.external_references RETURN ref)
    FILTER extRef.source_name == "mitre-attack"
    LIMIT 1
    RETURN extRef.external_id
  )[0]
  SORT attack_id
  RETURN {{
    id: doc.id,
    attack_id: attack_id,
    name: doc.name,
    description: doc.description
  }}
"""

csv_headers = ["id", "attack_id", "name", "description"]

for collection in collections:
    # Initialize CSV file
    csv_file = f"{collection}.csv"
    
    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=csv_headers)
        writer.writeheader()

        # Pagination loop using cursor
        aql_query = aql_template.format(collection=collection)
        query_url = f"{arangodb_host}/_db/{database_name}/_api/cursor"
        response = requests.post(query_url, json={"query": aql_query, "batchSize": chunk_size}, auth=(arangodb_user, arangodb_password))
        response.raise_for_status()

        result = response.json()
        total_fetched = 0

        while True:
            documents = result.get("result", [])

            # Write the current chunk to the CSV file
            if documents:
                for doc in documents:
                    writer.writerow(doc)
                total_fetched += len(documents)
                print(f"Fetched {len(documents)} documents from {collection}, total fetched: {total_fetched}")
            else:
                break

            # Check if we have more documents to fetch
            if not result.get("hasMore"):
                break

            # Fetch the next batch using the cursor ID
            cursor_id = result.get("id")
            response = requests.put(f"{query_url}/{cursor_id}", auth=(arangodb_user, arangodb_password))
            response.raise_for_status()
            result = response.json()

    print(f"Total fetched documents from {collection}: {total_fetched}")
    print(f"Results have been written to {csv_file}")

```

Will create 3 CSVs (for each ATT&CK domain) that look like this;

```txt
id,attack_id,name,description
campaign--26d9ebae-de59-427f-ae9a-349456bae4b1,C0001,Frankenstein,"[Frankenstein](https://attack.mitre.org/campaigns/C0001) was described by security researchers as a highly-targeted campaign conducted by moderately sophisticated and highly resourceful threat actors in early 2019. The unidentified actors primarily relied on open source tools, including [Empire](https://attack.mitre.org/software/S0363). The campaign name refers to the actors' ability to piece together several unrelated open-source tool components.(Citation: Talos Frankenstein June 2019)"
campaign--ae407e32-87e0-4d92-8705-3ae25d504d8a,C0002,Night Dragon,"[Night Dragon](https://attack.mitre.org/campaigns/C0002) was a cyber espionage campaign that targeted oil, energy, and petrochemical companies, along with individuals and executives in Kazakhstan, Taiwan, Greece, and the United States. The unidentified threat actors searched for information related to oil and gas field production systems, financials, and collected data from SCADA systems. Based on the observed techniques, tools, and network activities, security researchers assessed the campaign involved a threat group based in China.(Citation: McAfee Night Dragon)"
```

In total there are 1991 ATT&CK objects returned by this query (for the Enterprise domain). You can of course trim it to only include objects you care about, e.g. only using `doc.type == "attack-pattern"` in the `aql_template` will return just Techniques and Subtechniques

```sql
FOR doc IN mitre_attack_enterprise_vertex_collection
  FILTER doc._stix2arango_note != "automatically imported on collection creation"
  AND doc._stix2arango_note == "v15.1"
  AND (
    doc.type == "attack-pattern"
  )
  LET attack_id = (
    FOR extRef IN (FOR ref IN doc.external_references RETURN ref)
    FILTER extRef.source_name == "mitre-attack"
    LIMIT 1
    RETURN extRef.external_id
  )[0]
  SORT attack_id
  COLLECT WITH COUNT INTO length
    RETURN length
```

```json
[
  780
]
```

You could then prime the LLM with the prompt (ensure you submit the appropriate files too);

```txt
These three csv files contain version 15.1 of the MITRE ATT&CK framework. Each csv represents a different ATT&CK domain, as follows;

1. mitre_attack_enterprise_vertex_collection.csv: This domain is designed to cover tactics and techniques used in traditional enterprise IT environments. It encompasses a broad range of devices, networks, and applications typically found in business settings.
mitre_attack_ics_vertex_collection.csv: This domain focuses on tactics and techniques specifically tailored to mobile devices such as smartphones and tablets.
mitre_attack_enterprise_vertex_collection.csv: This domain is designed to address tactics and techniques used against industrial control systems, which are crucial for operating critical infrastructure such as power grids, water treatment facilities, manufacturing plants, and other industrial environments.

All csv files have the schema;

id,attack_id,name,description

Where;

* id: is the STIX ID for the record
* attack_id: is the MITRE ATT&CK ID for the record
* name: is the name of the record
* description: is a description of the record

The attack_id related to different ATT&CK objects types as follows;

* Tactics have IDs in format: TANNNN
* Techniques have IDs in format: TNNNN 
* Sub-techniques have IDs in format: TNNNN.NNN
* Mitigations have IDs in format: MNNNN (and sometimes TNNNN)
* Groups have IDs in format: GNNNN
* Software have IDs in format: SNNNN
* Tools also have IDs in format: SNNNN
* Campaigns have IDs in format: CNNNN
* Data Sources have IDs in format: DSNNNN
```

## Linking AI response with MITRE ATT&CK STIX objects

So, to continue my proof of concept, lets assume my confidence threshold is >= 0.7 (so all the entries returned earlier match my filter). Using this information I can now link the detected ATT&CK object IDs.

I can use a CTI Butler query to do this;

```sql
LET ATTACK_IDS = [
    "T1005",
    "T1586",
    "T1589"
]

LET enterprise_results = (
    FOR doc IN mitre_attack_enterprise_vertex_collection
        FILTER doc._stix2arango_note != "automatically imported on collection creation"
        AND doc._stix2arango_note == "v15.1"
        AND (doc.type != "x-mitre-collection" AND doc.type != "marking-definition" AND doc.type != "identity" AND doc.type != "x-mitre-matrix" AND doc.type != "x-mitre-data-component")
        AND doc.external_references != null AND IS_ARRAY(doc.external_references)
        FOR extRef IN doc.external_references
            FILTER extRef.external_id IN ATTACK_IDS
            AND extRef.source_name == "mitre-attack"
            RETURN {
                id: doc.id,
                attack_id: extRef.external_id,
                name: doc.name,
                type: doc.type,
                collection: "enterprise"
            }
)

LET ics_results = (
    FOR doc IN mitre_attack_ics_vertex_collection
        FILTER doc._stix2arango_note != "automatically imported on collection creation"
        AND doc._stix2arango_note == "v15.1"
        AND (doc.type != "x-mitre-collection" AND doc.type != "marking-definition" AND doc.type != "identity" AND doc.type != "x-mitre-matrix" AND doc.type != "x-mitre-data-component")
        AND doc.external_references != null AND IS_ARRAY(doc.external_references)
        FOR extRef IN doc.external_references
            FILTER extRef.external_id IN ATTACK_IDS
            AND extRef.source_name == "mitre-attack"
            RETURN {
                id: doc.id,
                attack_id: extRef.external_id,
                name: doc.name,
                type: doc.type,
                collection: "ics"
            }
)

LET mobile_results = (
    FOR doc IN mitre_attack_mobile_vertex_collection
        FILTER doc._stix2arango_note != "automatically imported on collection creation"
        AND doc._stix2arango_note == "v15.1"
        AND (doc.type != "x-mitre-collection" AND doc.type != "marking-definition" AND doc.type != "identity" AND doc.type != "x-mitre-matrix" AND doc.type != "x-mitre-data-component")
        AND doc.external_references != null AND IS_ARRAY(doc.external_references)
        FOR extRef IN doc.external_references
            FILTER extRef.external_id IN ATTACK_IDS
            AND extRef.source_name == "mitre-attack"
            RETURN {
                id: doc.id,
                attack_id: extRef.external_id,
                name: doc.name,
                type: doc.type,
                collection: "mobile"
            }
)

RETURN UNION_DISTINCT(
    enterprise_results,
    ics_results,
    mobile_results
)
```

```json
[
  [
    {
      "id": "attack-pattern--5282dd9a-d26d-4e16-88b7-7c0f4553daf4",
      "attack_id": "T1589",
      "name": "Gather Victim Identity Information",
      "type": "attack-pattern",
      "collection": "enterprise"
    },
    {
      "id": "attack-pattern--3c4a2599-71ee-4405-ba1e-0e28414b4bc5",
      "attack_id": "T1005",
      "name": "Data from Local System",
      "type": "attack-pattern",
      "collection": "enterprise"
    },
    {
      "id": "course-of-action--7ee0879d-ce4f-4f54-a96b-c532dfb98ffd",
      "attack_id": "T1005",
      "name": "Data from Local System Mitigation",
      "type": "course-of-action",
      "collection": "enterprise"
    },
    {
      "id": "attack-pattern--81033c3b-16a4-46e4-8fed-9b030dd03c4a",
      "attack_id": "T1586",
      "name": "Compromise Accounts",
      "type": "attack-pattern",
      "collection": "enterprise"
    }
  ]
]
```

Note, you might want to exclude the COA returned as it is linked to the Technique `T1005`.

Therefore I now have enough information to link a CVE to all ATT&CK objects. I will do this with STIX relationship object modelled as follows;

```json
{
    "type": "relationship",
    "spec_version": "2.1",
    "id": "relationship--<UUID V5>",
    "created_by_ref": "identity--<ARANGO_CTI_PROCESSOR_ID>",
    "created": "<VULNERABILITY CREATED TIME>",
    "modified": "<VULNERABILITY MODIFIED TIME>",
    "relationship_type": "mitre-attack",
    "source_ref": "vulnerability--<ID>",
    "target_ref": "<MITRE ATTACK OBJECT ID>",
    "object_marking_refs": [
        "marking-definition--94868c89-83c2-464b-929b-a1a8aa3c8487",
        "marking-definition--<ARANGO_CTI_PROCESSOR_ID>"
    ]
}
```

e.g. for CVE-2016-6587 you'd have three STIX relationship objects created.

All 3 would have a `source_ref==vulnerability--620f4cb1-67db-57bb-b7b0-81f6c1b45519`

And `target_ref`s for each would be:

1. `attack-pattern--81033c3b-16a4-46e4-8fed-9b030dd03c4a`
2. `attack-pattern--3c4a2599-71ee-4405-ba1e-0e28414b4bc5`
3. `attack-pattern--5282dd9a-d26d-4e16-88b7-7c0f4553daf4`

## In summary

Now I can search CTI Butler for CVEs using ATT&CK objects as the source.

For example, if I wanted to retrieve all Vulnerabilities related to the ATT&CK Technique, Data from Local System (T1005 / `attack-pattern--3c4a2599-71ee-4405-ba1e-0e28414b4bc5`), I could run the query...

```sql
FOR edge_doc IN mitre_attack_enterprise_edge_collection
FILTER edge_doc.target_ref == "attack-pattern--3c4a2599-71ee-4405-ba1e-0e28414b4bc5"
AND edge_doc.relationship_type == "mitre-attack"
AND edge_doc.source_ref LIKE "vulnerability--%"
FOR vertex_doc IN mitre_attack_enterprise_vertex_collection
FILTER vertex_doc.id == edge_doc.source_ref
LET cleaned_doc = KEEP(vertex_doc, ATTRIBUTES(vertex_doc, true) FILTER LIKE(CURRENT, "_%", false))
RETURN cleaned_doc
```